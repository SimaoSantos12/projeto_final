{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76203cf-e1e8-44f7-9d71-c630bf304795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7772f840-a3cb-48ca-aa00-572adbd110a9",
   "metadata": {},
   "source": [
    "Calcula estatisticas e taxas de enchimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4f0c9-b28b-4946-9206-f21265ce3988",
   "metadata": {},
   "source": [
    "Tempo: 2 horas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e927146-c8df-44e0-b236-1005542ac8d8",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f572f8e-2378-4e34-8663-592d52ab2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3(x):\n",
    "    \"\"\"\n",
    "    Calcula o primeiro e terceiro quartil\n",
    "    \"\"\"\n",
    "    return x.quantile(0.75)\n",
    "\n",
    "def q1(x):\n",
    "    return x.quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ddc472e-e6ee-4832-aec9-3137671cf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_stats(df, window):\n",
    "    \"\"\"\n",
    "    Calcula estatísticas deslizantes (rolling window) por grupo com base em colunas específicas.\n",
    "\n",
    "    Para cada combinação de 'info_adicional', 'local_id' e 'tipo', aplica uma janela deslizante\n",
    "    de `window` dias sobre as colunas 'delta_nivel', 'delta_tempo_horas' e 'taxa_enchimento_hora',\n",
    "    após aplicar um shift (deslocamento) de 1 (este shift evita que use o proprio dia). Em seguida, calcula as estatisticas (média, mínimo, máximo, mediana, desvio padrão, Q1 e Q3).\n",
    "    \"\"\"\n",
    "     \n",
    "    # Ordena e define o índice\n",
    "    df_sorted = df.sort_values('data')\n",
    "\n",
    "    results = []\n",
    "    for _, group in df_sorted.groupby(['info_adicional', 'local_id', 'tipo']):\n",
    "        group = group.set_index('data').sort_index()\n",
    "        group.index = pd.to_datetime(group.index)  # Garante que o índice seja datetime\n",
    "\n",
    "        group_rolled = (\n",
    "            group[['delta_nivel', 'delta_tempo_horas', 'taxa_enchimento_hora']]\n",
    "            .shift(1)\n",
    "            .rolling(f'{window}D', min_periods=1)\n",
    "            .agg({\n",
    "                'delta_nivel': ['mean', 'min', 'max', 'median', 'std', q1, q3],\n",
    "                'delta_tempo_horas': ['mean', 'min', 'max', 'median', 'std', q1, q3],\n",
    "                'taxa_enchimento_hora': ['mean', 'min', 'max', 'median', 'std', q1, q3]\n",
    "            })\n",
    "        )\n",
    "\n",
    "        # Renomeia colunas\n",
    "        group_rolled.columns = [\n",
    "            f\"{col[0]}_{col[1]}\" if not isinstance(col[1], str) else f\"{col[0]}_{col[1]}\"\n",
    "            for col in group_rolled.columns\n",
    "        ]\n",
    "        \n",
    "        group_result = group_rolled.copy()\n",
    "        group_result[['info_adicional', 'local_id', 'tipo']] = group[['info_adicional', 'local_id', 'tipo']]\n",
    "        group_result = group_result.reset_index()\n",
    "        results.append(group_result)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad23c81e-9321-4770-b5fb-b3982fd4b0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_stats_nivel(df, window):\n",
    "    \"\"\"\n",
    "    Calcula estatísticas deslizantes sobre o nível de enchimento, no momento da recolha.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filtra apenas recolha == 0\n",
    "    df = df[df['recolha'] == 0]\n",
    "    \n",
    "    df_sorted = df.sort_values('data')\n",
    "\n",
    "    results = []\n",
    "    for _, group in df_sorted.groupby(['info_adicional', 'local_id', 'tipo']):\n",
    "        group = group.set_index('data').sort_index()\n",
    "        group.index = pd.to_datetime(group.index)  # Garante que o índice seja datetime\n",
    "\n",
    "        # Rolling com agregações, incluindo quartis\n",
    "        group_rolled = (\n",
    "            group[['nivel']]\n",
    "            .shift(1)\n",
    "            .rolling(f'{window}D', min_periods=1)\n",
    "            .agg(['mean', 'min', 'max', 'median', 'std', q1, q3])\n",
    "        )\n",
    "\n",
    "       # Renomeia colunas\n",
    "        group_rolled.columns = [\n",
    "            f\"{col[0]}_{col[1]}\" if not isinstance(col[1], str) else f\"{col[0]}_{col[1]}\"\n",
    "            for col in group_rolled.columns\n",
    "        ]\n",
    "        # Adiciona colunas de identificação\n",
    "        group_result = group_rolled.copy()\n",
    "        group_result[['info_adicional', 'local_id', 'tipo']] = group[['info_adicional', 'local_id', 'tipo']]\n",
    "        group_result = group_result.reset_index()\n",
    "        results.append(group_result)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2a5654-b4a5-48c7-9e9d-d32b49ccc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def met_1(df):\n",
    "\n",
    "    \"\"\"\n",
    "    Aplica um método de imputação e preparação de dados de nível para análise de enchimento.\n",
    "    Esta função trata registos com nível igual a zero, substituindo-os por valores médios por\n",
    "    combinação de ('local_id', 'tipo', 'cluster', 'info_adicional'). Em seguida, ordena e\n",
    "    estrutura os dados para cálculo de variações (deltas) de nível e tempo, removendo\n",
    "    inconsistências como deltas negativos.\n",
    "\n",
    "    Etapas principais:\n",
    "    - Separa registos com `nivel == 0`. (observacoes das recolhas)\n",
    "    - Calcula a média do nível por grupo (das observacoes quando existe mais do que uma observacao para o mesmo tipo no mesmo cluster).\n",
    "    - Insere uma linha representativa com a média para cada grupo.\n",
    "    - Coloca primeiro as linhas onde o nivel é 0 e depois as observacoes para poder aferir qual o valor que foi recolhido (que será o proximo valor do mesmo tipo)\n",
    "    - Ordena os dados, calcula a próxima medição de nível (`prox_nivel`), e aplica função de deltas.\n",
    "    - Remove-se as linhas com nivel 0, pois apenas são uteis para saber qual valor foi recolhido e remove-se onde os deltas são negativos.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    # Separar linhas com nivel == 0\n",
    "    df_nivel_zero = df[df['nivel'] == 0].copy()\n",
    "    \n",
    "    # Linhas com nivel != 0\n",
    "    df_nivel_positivo = df[df['nivel'] != 0].copy()\n",
    "\n",
    "    # Calcular média por tipo e cluster, arredondada\n",
    "    media_por_tipo_cluster = (\n",
    "                                df_nivel_positivo\n",
    "                                .groupby(['local_id', 'tipo', 'cluster', 'info_adicional'])['nivel']\n",
    "                                .mean()\n",
    "                                #.round()\n",
    "                                #.astype(int)\n",
    "                                .reset_index()\n",
    "                            )\n",
    "\n",
    "    # Obter uma linha representativa por tipo+cluster+local_id+info_adicional\n",
    "    df_unico_por_tipo_cluster = (\n",
    "                                    df_nivel_positivo.sort_values(by='time')\n",
    "                                    .drop_duplicates(subset=['local_id', 'tipo', 'cluster', 'info_adicional'])\n",
    "                                    .merge(media_por_tipo_cluster, on=['local_id', 'tipo', 'cluster', 'info_adicional'], suffixes=('', '_media'))\n",
    "                                    .drop(columns=['nivel'])\n",
    "                                    .rename(columns={'nivel_media': 'nivel'})\n",
    "                            )\n",
    "\n",
    "    # Concatenar com as linhas de nível 0\n",
    "    df_resultado = pd.concat([df_nivel_zero, df_unico_por_tipo_cluster], ignore_index=True)\n",
    "    \n",
    "    # Ordenar: primeiro os de nível ≠ 0, depois os 0 (dentro de cada cluster)\n",
    "    df_resultado['nivel_zero_flag'] = (df_resultado['nivel'] == 0).astype(int)\n",
    "    df_resultado = df_resultado.sort_values(by=['cluster', 'nivel_zero_flag', 'timestamp', 'tipo']).reset_index(drop=True)\n",
    "    df_resultado.drop(columns='nivel_zero_flag', inplace=True)\n",
    "\n",
    "    # Adiciona a coluna 'prox_nivel' considerando o grupo correto\n",
    "    df_resultado['recolha'] = (\n",
    "                                df_resultado\n",
    "                                .groupby(['tipo', 'local_id', 'info_adicional', 'cluster'])['nivel']\n",
    "                                .shift(-1)\n",
    "                             ).fillna(1)\n",
    "\n",
    "\n",
    "    # Remover linhas com nível \n",
    "    df_resultado = df_resultado[df_resultado['nivel'] != 0].reset_index(drop=True)\n",
    "    \n",
    "    # Ordenar por tempo para cálculo dos deltas\n",
    "    df_resultado = df_resultado.sort_values(by='timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # Aplicar por grupo\n",
    "    df_resultado = (\n",
    "                        df_resultado\n",
    "                        .groupby(['local_id', 'tipo', 'info_adicional'], group_keys=False)\n",
    "                        .apply(calcular_deltas)\n",
    "                    )\n",
    "                    \n",
    "    df_resultado = df_resultado.sort_values(by=['timestamp', 'info_adicional', 'local_id', 'tipo']).reset_index(drop=True)\n",
    "    \n",
    "    #Remove linhas onde o delta é negativo\n",
    "    df_resultado = df_resultado[(df_resultado['delta_nivel'].isna()) | (df_resultado['delta_nivel'] >= 0)]    \n",
    "    \n",
    "    df_resultado.drop(columns='recolha_anterior', inplace=True)\n",
    "\n",
    "    return df_resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5199533-57c3-4f94-bbff-861163eb33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para aplicar por grupo\n",
    "def calcular_deltas(grupo):\n",
    "    \"\"\"\n",
    "    Calcula as diferenças (deltas) de nível e tempo entre observações consecutivas.\n",
    "    Faz a recolha do nivel anterior, que será 0 se o ponto foi recolhido ou o valor observado se não foi recolhido\n",
    "\n",
    "    \"\"\"\n",
    "  # Garante que o grupo está ordenado cronologicamente\n",
    "    grupo = grupo.sort_values(by='timestamp').copy()\n",
    "    \n",
    "    # Armazena o nível anterior real para cada linha\n",
    "    grupo['nivel_anterior_real'] = grupo['nivel'].shift(1)\n",
    "    \n",
    "    # Armazena a flag de recolha da linha anterior\n",
    "    grupo['recolha_anterior'] = grupo['recolha'].shift(1)\n",
    "    \n",
    "    # Se a recolha anterior foi 0 (ou seja, houve recolha), o nível anterior é 0.\n",
    "    # Caso contrário, usa o nível anterior real. Isso simula o reinício do contentor após recolha.\n",
    "    grupo['nivel_anterior'] = np.where(grupo['recolha_anterior'] == 0, 0, grupo['nivel_anterior_real'])\n",
    "    \n",
    "    # Timestamp da linha anterior\n",
    "    grupo['time_anterior'] = grupo['timestamp'].shift(1)\n",
    "    \n",
    "    # Diferença entre o nível atual e o anterior \n",
    "    grupo['delta_nivel'] = grupo['nivel'] - grupo['nivel_anterior']\n",
    "    \n",
    "    # Diferença de tempo entre observações consecutivas\n",
    "    grupo['delta_tempo'] = grupo['timestamp'] - grupo['time_anterior']\n",
    "    \n",
    "    # Converte o delta de tempo para horas \n",
    "    grupo['delta_tempo_horas'] = grupo['delta_tempo'].dt.total_seconds() / 3600\n",
    "    \n",
    "    # Taxa de enchimento por hora = variação de nível / tempo passado\n",
    "    grupo['taxa_enchimento_hora'] = grupo['delta_nivel'] / grupo['delta_tempo_horas']\n",
    "    \n",
    "    # Retorna o DataFrame com as novas colunas calculadas\n",
    "    return grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c80b1b8-74b1-4796-839c-a9a9b5b7931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process():\n",
    "    \"\"\"\n",
    "    Realiza o pré-processamento dos dados de nível a partir de múltiplas fontes e aplica clusterização temporal, normaliza o nome dos circuitos\n",
    "    e agrupa os eventos em clusters de 5 minutos (info_adicional e local_id)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    df1 = pd.read_excel(\"../data/raw/seletiva_nivel.xlsx\", sheet_name='Result 1')\n",
    "    df2 = pd.read_excel(\"../data/raw/seletiva_nivel.xlsx\", sheet_name='Result 2')\n",
    "\n",
    "    seletiva_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    locais_path = \"../data/raw/locais.xlsx\"\n",
    "    locais_df = pd.read_excel(locais_path)\n",
    "        \n",
    "    seletiva_df = seletiva_df.drop(columns=['produto_id'])\n",
    "    seletiva_df = seletiva_df.drop(columns=['local_uuid_id'])#Remover as colunas que não interessam\n",
    "    seletiva_df = seletiva_df[seletiva_df['local_id'] != 6394] #Este ponto é removido pois ao criar as rotas com o openrouteservice dá erro devido às\n",
    "                                                               # suas coordenadas\n",
    "\n",
    "    locais_df.rename(columns={'id': 'local_id'}, inplace=True)\n",
    "\n",
    "    # Filtrar apenas os IDs comuns\n",
    "    ids_comuns = set(locais_df['local_id']).intersection(set(seletiva_df['local_id']))\n",
    "    seletiva_df = seletiva_df[seletiva_df['local_id'].isin(ids_comuns)]\n",
    "\n",
    "    substituicoes = {\n",
    "    'Circuito 03 32': 'Circuito 03',\n",
    "    'Cricuito 08': 'Circuito 08',\n",
    "    'Circ. Ilhas S': 'Circ. Ilhas',\n",
    "    'circuito 05': 'Circuito 05',\n",
    "    'Circ. Ilhas 04': 'Circ. Ilhas',\n",
    "    'Circuito 09 92': 'Circuito 09',\n",
    "    'Circuito Ilhas': 'Circ. Ilhas'\n",
    "    }\n",
    "\n",
    "    # Ignorar linhas com circuitos \"via recolha\" ou \"GP 91\"\n",
    "    seletiva_df = seletiva_df[~seletiva_df['info_adicional'].str.lower().isin(['via recolha', 'gp 91'])]\n",
    "    \n",
    "    # Aplicar substituições\n",
    "    seletiva_df['info_adicional'] = seletiva_df['info_adicional'].replace(substituicoes)\n",
    "\n",
    "        \n",
    "    seletiva_df['time'] = pd.to_datetime(seletiva_df['time'], errors='coerce')\n",
    "    seletiva_df['data'] = seletiva_df['time'].dt.date\n",
    "\n",
    "    #  Conversão da coluna 'time' para timestamp\n",
    "    seletiva_df['timestamp'] = pd.to_datetime(seletiva_df['time'], format='mixed')\n",
    "\n",
    "    #  Definição do threshold de 5 minutos\n",
    "    threshold = pd.Timedelta(minutes=5)\n",
    "    \n",
    "    # Ordenação para garantir que .diff() funcione bem\n",
    "    df = seletiva_df.sort_values(by=['info_adicional', 'local_id', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "    #  Aplicação da clusterização por (info_adicional, local_id)\n",
    "    df = df.groupby(['info_adicional', 'local_id'], group_keys=False).apply(cluster_sessions)\n",
    "\n",
    "    # Substitui o timestamp por cluster_start (primeiro timestamp do cluster)\n",
    "    df['timestamp'] = df.groupby(['info_adicional', 'local_id', 'cluster'])['timestamp'].transform('first')\n",
    "\n",
    "    df.drop(columns='time_diff', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5252fc5-3afd-4e9c-8740-c42f6d53fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sessions(group):\n",
    "    \"\"\"\n",
    "    Agrupa eventos de um mesmo grupo (info_adicional e local_id) em clusters de 5 minutos.\n",
    "    Um novo cluster é iniciado sempre que o intervalo entre dois eventos consecutivos\n",
    "    for maior que 5 minutos.\n",
    "    \"\"\"\n",
    "    threshold = pd.Timedelta(minutes=5)\n",
    "    group = group.copy()\n",
    "    group['time_diff'] = group['timestamp'].diff()\n",
    "    group['cluster'] = (group['time_diff'] > threshold).cumsum()\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a605b80-8b94-4421-93ca-5b250b28ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_merge_base():\n",
    "    \"\"\"\n",
    "    Lê o ficheiro com as instancias e cria um df com as instancias presentes nesse ficheiro.\n",
    "    Renomeia os circuitos para ficarem com os mesmos nomes do df_resultado\n",
    "    \"\"\"\n",
    "    \n",
    "    caminho = \"../data/tabela_observacao_recolha.csv\"\n",
    "    df_pontos = pd.read_csv(caminho, delimiter=';')\n",
    "\n",
    "    df_pontos=df_pontos[['Data', 'Circuito', 'Tipo', 'local_id']]\n",
    "\n",
    "    df_merge_base = df_pontos.rename(columns={\n",
    "    'Data': 'data',\n",
    "    'Circuito': 'info_adicional',\n",
    "    'Tipo': 'tipo'\n",
    "    })\n",
    "\n",
    "    substituicoes = {\n",
    "    'Circ_Ilhas': 'Circ. Ilhas',\n",
    "    'Circuito_01': 'Circuito 01',\n",
    "    'Circuito_02': 'Circuito 02',\n",
    "    'Circuito_03': 'Circuito 03',\n",
    "    'Circuito_04': 'Circuito 04',\n",
    "    'Circuito_05': 'Circuito 05',\n",
    "    'Circuito_06': 'Circuito 06',\n",
    "    'Circuito_07': 'Circuito 07',\n",
    "    'Circuito_08': 'Circuito 08',\n",
    "    'Circuito_09': 'Circuito 09',\n",
    "    'Circuito_10': 'Circuito 10',\n",
    "    'Circuito_11': 'Circuito 11',\n",
    "    'Circuito_12': 'Circuito 12',\n",
    "    }\n",
    "\n",
    "    df_merge_base['info_adicional'] = df_merge_base['info_adicional'].replace(substituicoes)\n",
    "\n",
    "    return df_merge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "315aa5c3-4656-48a5-9682-940a542dcf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_cartesian(df):\n",
    "    \"\"\"\n",
    "    Gera um DataFrame que representa o produto cartesiano entre um conjunto de datas\n",
    "    fixas e as combinações únicas de grupos definidas pelas colunas\n",
    "    'info_adicional', 'local_id' e 'tipo' presentes no DataFrame de entrada.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Datas de interesse\n",
    "    all_dates = pd.date_range(start='2024-01-02', end='2024-12-31', freq='D')\n",
    "    \n",
    "    # Combinações únicas de grupos\n",
    "    group_keys = df[['info_adicional', 'local_id', 'tipo']].drop_duplicates()\n",
    "    \n",
    "    # Produto cartesiano entre datas e grupos\n",
    "    full_index = (\n",
    "        group_keys.assign(key=1)\n",
    "        .merge(pd.DataFrame({'data': all_dates, 'key': 1}), on='key')\n",
    "        .drop(columns='key')\n",
    "    )\n",
    "\n",
    "    full_index['data'] = pd.to_datetime(full_index['data'])\n",
    "    df['data'] = pd.to_datetime(df['data'])\n",
    "\n",
    "    df_full = full_index.merge(df, on=['data', 'info_adicional', 'local_id', 'tipo'], how='left')\n",
    "    return df_full\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a5afad-ad1e-4721-b761-87f540d4b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_estats(df):\n",
    "    \"\"\"\n",
    "    Calcula estatísticas móveis (rolling statistics) para diferentes janelas de tempo\n",
    "    (30 e 90 dias) sobre as colunas relacionadas a níveis e taxas, aplicando agregações\n",
    "    como média, mínimo, máximo, mediana, desvio padrão e quartis (Q1 e Q3).\n",
    "\n",
    "    A função também renomeia as colunas resultantes para facilitar a identificação\n",
    "    das estatísticas por janela e tipo de métrica.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    rolling_1m = rolling_stats(df, 30)\n",
    "    rolling_3m = rolling_stats(df, 90)\n",
    "\n",
    "    rolling_1m_nivel = rolling_stats_nivel(df, 30)\n",
    "    rolling_3m_nivel = rolling_stats_nivel(df, 90)\n",
    "\n",
    "        # Flatten colunas se ainda forem MultiIndex\n",
    "    if isinstance(rolling_1m.columns, pd.MultiIndex):\n",
    "        rolling_1m.columns = [\n",
    "            f\"{col[0]}_{col[1]}\" if col[1] else col[0]\n",
    "            for col in rolling_1m.columns\n",
    "        ]\n",
    "    # Flatten colunas se ainda forem MultiIndex\n",
    "    if isinstance(rolling_3m.columns, pd.MultiIndex):\n",
    "        rolling_3m.columns = [\n",
    "            f\"{col[0]}_{col[1]}\" if col[1] else col[0]\n",
    "            for col in rolling_3m.columns\n",
    "        ]\n",
    "    # Flatten colunas se ainda forem MultiIndex\n",
    "    if isinstance(rolling_1m_nivel.columns, pd.MultiIndex):\n",
    "        rolling_1m_nivel.columns = [\n",
    "            f\"{col[0]}_{col[1]}\" if col[1] else col[0]\n",
    "            for col in rolling_1m_nivel.columns\n",
    "        ]\n",
    "    # Flatten colunas se ainda forem MultiIndex\n",
    "    if isinstance(rolling_3m_nivel.columns, pd.MultiIndex):\n",
    "        rolling_3m_nivel.columns = [\n",
    "            f\"{col[0]}_{col[1]}\" if col[1] else col[0]\n",
    "            for col in rolling_3m_nivel.columns\n",
    "        ]\n",
    "\n",
    "    rename_dict_mes = {\n",
    "        'delta_nivel_mean': 'dn_mean_1m',\n",
    "        'delta_nivel_min': 'dn_min_1m',\n",
    "        'delta_nivel_max': 'dn_max_1m',\n",
    "        'delta_nivel_median': 'dn_median_1m',\n",
    "        'delta_nivel_std': 'dn_std_1m',\n",
    "        'delta_nivel_q1' : 'dn_1m_q1',\n",
    "        'delta_nivel_q3' : 'dn_1m_q3',\n",
    "\n",
    "    \n",
    "        'delta_tempo_horas_mean': 'dt_mean_1m',\n",
    "        'delta_tempo_horas_min': 'dt_min_1m',\n",
    "        'delta_tempo_horas_max': 'dt_max_1m',\n",
    "        'delta_tempo_horas_median': 'dt_median_1m',\n",
    "        'delta_tempo_horas_std': 'dt_std_1m',\n",
    "        'delta_tempo_horas_q1': 'dt_1m_q1',\n",
    "        'delta_tempo_horas_q3': 'dt_1m_q3',\n",
    "\n",
    "\n",
    "    \n",
    "        'taxa_enchimento_hora_mean': 'te_mean_1m',\n",
    "        'taxa_enchimento_hora_min': 'te_min_1m',\n",
    "        'taxa_enchimento_hora_max': 'te_max_1m',\n",
    "        'taxa_enchimento_hora_median': 'te_median_1m',\n",
    "        'taxa_enchimento_hora_std': 'te_std_1m',\n",
    "        'taxa_enchimento_hora_q1': 'te_1m_q1',\n",
    "        'taxa_enchimento_hora_q3': 'te_1m_q3'\n",
    "\n",
    "        \n",
    "        }\n",
    "\n",
    "\n",
    "    rename_dict_trimestral = {\n",
    "        'delta_nivel_mean': 'dn_mean_3m',\n",
    "        'delta_nivel_min': 'dn_min_3m',\n",
    "        'delta_nivel_max': 'dn_max_3m',\n",
    "        'delta_nivel_median': 'dn_median_3m',\n",
    "        'delta_nivel_std': 'dn_std_3m',\n",
    "        'delta_nivel_q1' : 'dn_3m_q1',\n",
    "        'delta_nivel_q3' : 'dn_3m_q3',\n",
    "\n",
    "    \n",
    "        'delta_tempo_horas_mean': 'dt_mean_3m',\n",
    "        'delta_tempo_horas_min': 'dt_min_3m',\n",
    "        'delta_tempo_horas_max': 'dt_max_3m',\n",
    "        'delta_tempo_horas_median': 'dt_median_3m',\n",
    "        'delta_tempo_horas_std': 'dt_std_3m',\n",
    "        'delta_tempo_horas_q1': 'dt_3m_q1',\n",
    "        'delta_tempo_horas_q3': 'dt_3m_q3',\n",
    "        \n",
    "    \n",
    "        'taxa_enchimento_hora_mean': 'te_mean_3m',\n",
    "        'taxa_enchimento_hora_min': 'te_min_3m',\n",
    "        'taxa_enchimento_hora_max': 'te_max_3m',\n",
    "        'taxa_enchimento_hora_median': 'te_median_3m',\n",
    "        'taxa_enchimento_hora_std': 'te_std_3m',\n",
    "        'taxa_enchimento_hora_q1': 'te_3m_q1',\n",
    "        'taxa_enchimento_hora_q3': 'te_3m_q3'\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    }\n",
    "    rename_dict_mes_nivel = {\n",
    "    \n",
    "        'nivel_mean' : 'rec_mean_1m',          \n",
    "        'nivel_min' :   'rec_min_1m',      \n",
    "        'nivel_max' : 'rec_max_1m',         \n",
    "        'nivel_median' : 'rec_median_1m',          \n",
    "        'nivel_std' : 'rec_std_1m',\n",
    "        'nivel_q1' : 'rec_1m_q1',\n",
    "        'nivel_q3' : 'rec_1m_q3'\n",
    "\n",
    "    \n",
    "    }\n",
    "    \n",
    "    rename_dict_trimestral_nivel = {\n",
    "    \n",
    "        'nivel_mean' : 'rec_mean_3m',          \n",
    "        'nivel_min' :   'rec_min_3m',      \n",
    "        'nivel_max' : 'rec_max_3m',         \n",
    "        'nivel_median' : 'rec_median_3m',          \n",
    "        'nivel_std' : 'rec_std_3m',\n",
    "        'nivel_q1' : 'rec_3m_q1',\n",
    "        'nivel_q3' : 'rec_3m_q3'\n",
    "    \n",
    "    }\n",
    "\n",
    "    rolling_1m = rolling_1m.rename(columns=rename_dict_mes)\n",
    "    rolling_3m = rolling_3m.rename(columns=rename_dict_trimestral)\n",
    "    rolling_1m_nivel = rolling_1m_nivel.rename(columns=rename_dict_mes_nivel)\n",
    "    rolling_3m_nivel = rolling_3m_nivel.rename(columns=rename_dict_trimestral_nivel)\n",
    "\n",
    "    \n",
    "    \n",
    "    rolling_1m = rolling_1m.groupby(['data', 'info_adicional', 'tipo', 'local_id']).first().reset_index()\n",
    "    rolling_3m = rolling_3m.groupby(['data', 'info_adicional', 'tipo', 'local_id']).first().reset_index()\n",
    "    rolling_1m_nivel = rolling_1m_nivel.groupby(['data', 'info_adicional', 'tipo', 'local_id']).first().reset_index()\n",
    "    rolling_3m_nivel = rolling_3m_nivel.groupby(['data', 'info_adicional', 'tipo', 'local_id']).first().reset_index()\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    return rolling_1m, rolling_3m, rolling_1m_nivel, rolling_3m_nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "331da1e5-5106-40b5-ab0e-2e9eca4f7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df_merge_base, rolling_1m, rolling_3m, rolling_1m_nivel, rolling_3m_nivel):\n",
    "    \"\"\"\n",
    "    Faz o merge do df das instancias com os dfs das estatisticas com base nas colunas\n",
    "    ['data', 'info_adicional', 'local_id', 'tipo'], garantindo que as datas\n",
    "    estão no formato datetime com o parâmetro dayfirst=True.\n",
    "    Aplica também substituições específicas na coluna 'info_adicional'.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_merge_base['data'] = pd.to_datetime(df_merge_base['data'], dayfirst=True)\n",
    "    rolling_1m['data'] = pd.to_datetime(rolling_1m['data'], dayfirst=True)\n",
    "    rolling_3m['data'] = pd.to_datetime(rolling_3m['data'], dayfirst=True)\n",
    "    rolling_1m_nivel['data'] = pd.to_datetime(rolling_1m_nivel['data'], dayfirst=True)\n",
    "    rolling_3m_nivel['data'] = pd.to_datetime(rolling_3m_nivel['data'], dayfirst=True)\n",
    "\n",
    "    df_final = (\n",
    "        df_merge_base\n",
    "        .merge(rolling_1m, on=['data', 'info_adicional', 'local_id', 'tipo'], how='left')\n",
    "        .merge(rolling_3m, on=['data', 'info_adicional', 'local_id', 'tipo'], how='left')\n",
    "        .merge(rolling_1m_nivel, on=['data', 'info_adicional', 'local_id', 'tipo'], how='left')\n",
    "        .merge(rolling_3m_nivel, on=['data', 'info_adicional', 'local_id', 'tipo'], how='left')\n",
    "        )\n",
    "\n",
    "    alterar = {\n",
    "    'Circ. Ilhas': 'Circ_Ilhas',\n",
    "    'Circuito 01': 'Circuito_01',\n",
    "    'Circuito 02': 'Circuito_02',\n",
    "    'Circuito 03': 'Circuito_03',\n",
    "    'Circuito 04': 'Circuito_04',\n",
    "    'Circuito 05': 'Circuito_05',\n",
    "    'Circuito 06': 'Circuito_06',\n",
    "    'Circuito 07': 'Circuito_07',\n",
    "    'Circuito 08': 'Circuito_08',\n",
    "    'Circuito 09': 'Circuito_09',\n",
    "    'Circuito 10': 'Circuito_10',\n",
    "    'Circuito 11': 'Circuito_11',\n",
    "    'Circuito 12': 'Circuito_12',\n",
    "    }\n",
    "\n",
    "\n",
    "    df_final['info_adicional'] = df_final['info_adicional'].replace(alterar)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3e852-6864-47fe-b2d9-1270ccea90cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c286209d-7f3d-49c9-ad24-f19b68852fae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18a39bd3-ca3c-4ec8-98f9-43d2968ceec5",
   "metadata": {},
   "source": [
    "# --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa74531-5e42-415f-80a3-b6d775466fcd",
   "metadata": {},
   "source": [
    "## Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a71c07cb-a774-4786-8207-995467e09659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pre_process()\n",
    "df_resultado=met_1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da768c71-7c24-427d-ad0b-21daed7319f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copia = df_resultado.copy()\n",
    "df_merge_base=prep_merge_base()\n",
    "#df_full=prod_cartesian(df_copia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29012512-4ef5-421a-a02f-cab8862c16a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ce5affc-c4ce-46c0-8719-31cb8eae524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copia[\"data\"] = pd.to_datetime(df_copia[\"data\"]).dt.normalize()\n",
    "df_merge_base[\"data\"] = pd.to_datetime(df_merge_base[\"data\"]).dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf755ae3-7047-4af3-b0a8-56399790ce63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>info_adicional</th>\n",
       "      <th>tipo</th>\n",
       "      <th>nivel</th>\n",
       "      <th>local_id</th>\n",
       "      <th>data</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cluster</th>\n",
       "      <th>recolha</th>\n",
       "      <th>nivel_anterior_real</th>\n",
       "      <th>nivel_anterior</th>\n",
       "      <th>time_anterior</th>\n",
       "      <th>delta_nivel</th>\n",
       "      <th>delta_tempo</th>\n",
       "      <th>delta_tempo_horas</th>\n",
       "      <th>taxa_enchimento_hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5280464</td>\n",
       "      <td>2024-01-02 04:20:43+00:00</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Embalagens</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3863</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>2024-01-02 04:20:43+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5280465</td>\n",
       "      <td>2024-01-02 04:20:43+00:00</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Vidro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3863</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>2024-01-02 04:20:43+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5280466</td>\n",
       "      <td>2024-01-02 04:20:49+00:00</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Embalagens</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3864</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>2024-01-02 04:20:49+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5280467</td>\n",
       "      <td>2024-01-02 04:20:49+00:00</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Vidro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3864</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>2024-01-02 04:20:49+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5280469</td>\n",
       "      <td>2024-01-02 04:32:14+00:00</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Embalagens</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3844</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>2024-01-02 04:32:14+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378417</th>\n",
       "      <td>6421094</td>\n",
       "      <td>2024-12-31 15:01:32+00:00</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Vidro</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4294</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2024-12-31 15:01:32+00:00</td>\n",
       "      <td>183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-12-30 18:03:42+00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 days 20:57:50</td>\n",
       "      <td>20.963889</td>\n",
       "      <td>0.095402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378418</th>\n",
       "      <td>6421097</td>\n",
       "      <td>2024-12-31 15:05:56+00:00</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Embalagens</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4396</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2024-12-31 15:05:56+00:00</td>\n",
       "      <td>186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-12-30 18:08:15+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 20:57:41</td>\n",
       "      <td>20.961389</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378423</th>\n",
       "      <td>6421106</td>\n",
       "      <td>2024-12-31 15:11:15+00:00</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Papel</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4296</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2024-12-31 15:11:15+00:00</td>\n",
       "      <td>186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-12-30 18:12:40+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0 days 20:58:35</td>\n",
       "      <td>20.976389</td>\n",
       "      <td>0.143018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378424</th>\n",
       "      <td>6421105</td>\n",
       "      <td>2024-12-31 15:11:15+00:00</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Vidro</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4296</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2024-12-31 15:11:15+00:00</td>\n",
       "      <td>186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-12-30 18:12:40+00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0 days 20:58:35</td>\n",
       "      <td>20.976389</td>\n",
       "      <td>0.143018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378425</th>\n",
       "      <td>6421111</td>\n",
       "      <td>2024-12-31 15:17:03+00:00</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Embalagens</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4295</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2024-12-31 15:13:50+00:00</td>\n",
       "      <td>178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-12-30 18:19:29+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 20:54:21</td>\n",
       "      <td>20.905833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341601 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                      time info_adicional        tipo  nivel  \\\n",
       "0       5280464 2024-01-02 04:20:43+00:00    Circ. Ilhas  Embalagens    1.0   \n",
       "1       5280465 2024-01-02 04:20:43+00:00    Circ. Ilhas       Vidro    1.0   \n",
       "2       5280466 2024-01-02 04:20:49+00:00    Circ. Ilhas  Embalagens    1.0   \n",
       "3       5280467 2024-01-02 04:20:49+00:00    Circ. Ilhas       Vidro    1.0   \n",
       "4       5280469 2024-01-02 04:32:14+00:00    Circ. Ilhas  Embalagens    2.0   \n",
       "...         ...                       ...            ...         ...    ...   \n",
       "378417  6421094 2024-12-31 15:01:32+00:00    Circuito 12       Vidro    3.0   \n",
       "378418  6421097 2024-12-31 15:05:56+00:00    Circuito 12  Embalagens    5.0   \n",
       "378423  6421106 2024-12-31 15:11:15+00:00    Circuito 12       Papel    3.0   \n",
       "378424  6421105 2024-12-31 15:11:15+00:00    Circuito 12       Vidro    4.0   \n",
       "378425  6421111 2024-12-31 15:17:03+00:00    Circuito 12  Embalagens    5.0   \n",
       "\n",
       "        local_id       data                 timestamp  cluster  recolha  \\\n",
       "0           3863 2024-01-02 2024-01-02 04:20:43+00:00        0      1.0   \n",
       "1           3863 2024-01-02 2024-01-02 04:20:43+00:00        0      1.0   \n",
       "2           3864 2024-01-02 2024-01-02 04:20:49+00:00        0      1.0   \n",
       "3           3864 2024-01-02 2024-01-02 04:20:49+00:00        0      1.0   \n",
       "4           3844 2024-01-02 2024-01-02 04:32:14+00:00        0      1.0   \n",
       "...          ...        ...                       ...      ...      ...   \n",
       "378417      4294 2024-12-31 2024-12-31 15:01:32+00:00      183      1.0   \n",
       "378418      4396 2024-12-31 2024-12-31 15:05:56+00:00      186      0.0   \n",
       "378423      4296 2024-12-31 2024-12-31 15:11:15+00:00      186      1.0   \n",
       "378424      4296 2024-12-31 2024-12-31 15:11:15+00:00      186      1.0   \n",
       "378425      4295 2024-12-31 2024-12-31 15:13:50+00:00      178      0.0   \n",
       "\n",
       "        nivel_anterior_real  nivel_anterior             time_anterior  \\\n",
       "0                       NaN             NaN                       NaT   \n",
       "1                       NaN             NaN                       NaT   \n",
       "2                       NaN             NaN                       NaT   \n",
       "3                       NaN             NaN                       NaT   \n",
       "4                       NaN             NaN                       NaT   \n",
       "...                     ...             ...                       ...   \n",
       "378417                  1.0             1.0 2024-12-30 18:03:42+00:00   \n",
       "378418                  5.0             5.0 2024-12-30 18:08:15+00:00   \n",
       "378423                  5.0             0.0 2024-12-30 18:12:40+00:00   \n",
       "378424                  1.0             1.0 2024-12-30 18:12:40+00:00   \n",
       "378425                  5.0             5.0 2024-12-30 18:19:29+00:00   \n",
       "\n",
       "        delta_nivel     delta_tempo  delta_tempo_horas  taxa_enchimento_hora  \n",
       "0               NaN             NaT                NaN                   NaN  \n",
       "1               NaN             NaT                NaN                   NaN  \n",
       "2               NaN             NaT                NaN                   NaN  \n",
       "3               NaN             NaT                NaN                   NaN  \n",
       "4               NaN             NaT                NaN                   NaN  \n",
       "...             ...             ...                ...                   ...  \n",
       "378417          2.0 0 days 20:57:50          20.963889              0.095402  \n",
       "378418          0.0 0 days 20:57:41          20.961389              0.000000  \n",
       "378423          3.0 0 days 20:58:35          20.976389              0.143018  \n",
       "378424          3.0 0 days 20:58:35          20.976389              0.143018  \n",
       "378425          0.0 0 days 20:54:21          20.905833              0.000000  \n",
       "\n",
       "[341601 rows x 17 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04d8ace1-c7b5-4089-bf9b-c8b937d0c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de combinações únicas com recolha == 0: 3632\n"
     ]
    }
   ],
   "source": [
    "# Filtra apenas as linhas onde recolha == 0\n",
    "df_filtrado = df_copia[df_copia[\"recolha\"] == 0]\n",
    "\n",
    "# Seleciona as colunas desejadas e remove duplicadas\n",
    "df_unicos = df_filtrado[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates()\n",
    "\n",
    "# Conta quantas linhas únicas existem\n",
    "total_unicos = df_unicos.shape[0]\n",
    "\n",
    "print(f\"Número de combinações únicas com recolha == 0: {total_unicos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a668a26a-cce4-4d61-adec-72d69982e2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>info_adicional</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 07</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 09</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 10</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 08</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377578</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 04</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377592</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 06</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377609</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 10</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377640</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Vidro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377704</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3632 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             data info_adicional        tipo\n",
       "8      2024-01-02    Circ. Ilhas       Papel\n",
       "14     2024-01-02    Circuito 07       Papel\n",
       "27     2024-01-02    Circuito 09       Papel\n",
       "50     2024-01-02    Circuito 10       Papel\n",
       "55     2024-01-02    Circuito 08       Papel\n",
       "...           ...            ...         ...\n",
       "377578 2024-12-31    Circuito 04  Embalagens\n",
       "377592 2024-12-31    Circuito 06  Embalagens\n",
       "377609 2024-12-31    Circuito 10  Embalagens\n",
       "377640 2024-12-31    Circuito 12       Vidro\n",
       "377704 2024-12-31    Circuito 12  Embalagens\n",
       "\n",
       "[3632 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0169a647-de19-4adf-baf4-61a8920f52a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>info_adicional</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 07</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 09</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 10</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 08</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 06</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 03</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 09</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 11</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 11</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 05</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          data info_adicional        tipo\n",
       "8   2024-01-02    Circ. Ilhas       Papel\n",
       "14  2024-01-02    Circuito 07       Papel\n",
       "27  2024-01-02    Circuito 09       Papel\n",
       "50  2024-01-02    Circuito 10       Papel\n",
       "55  2024-01-02    Circuito 08       Papel\n",
       "62  2024-01-02    Circuito 06       Papel\n",
       "101 2024-01-02    Circuito 03  Embalagens\n",
       "104 2024-01-02    Circuito 09  Embalagens\n",
       "159 2024-01-02    Circuito 11  Embalagens\n",
       "638 2024-01-02    Circuito 11       Papel\n",
       "701 2024-01-02    Circuito 05  Embalagens\n",
       "967 2024-01-02    Circuito 12       Papel"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unicos_filtrado = df_unicos[df_unicos[\"data\"] == \"2024-01-02\"]\n",
    "df_unicos_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dada0eb-1678-4ab2-a02b-931e74081a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00650971-ffa5-4b9d-ba86-c2ebd5828507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fbde6d-f96e-4146-88d5-68f8abe9e271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0f1c4-f930-4b5e-8e81-2fc00d0b1870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c706c98-e60c-484b-9920-dcde488c4efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8509, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copia[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2506e41-b5df-4428-bbb0-4b6413df2e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4948, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_base[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f91367a6-f400-407b-9c74-36d5a0ff3049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>info_adicional</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>Circuito 03</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>Circuito 05</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>Circuito 06</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>Circuito 07</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361860</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 10</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361936</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 10</td>\n",
       "      <td>Vidro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362012</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 11</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362080</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362222</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Vidro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4948 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             data info_adicional        tipo\n",
       "0      2024-02-01    Circ. Ilhas       Papel\n",
       "42     2024-02-01    Circuito 03  Embalagens\n",
       "107    2024-02-01    Circuito 05  Embalagens\n",
       "180    2024-02-01    Circuito 06       Papel\n",
       "253    2024-02-01    Circuito 07       Papel\n",
       "...           ...            ...         ...\n",
       "361860 2024-12-31    Circuito 10  Embalagens\n",
       "361936 2024-12-31    Circuito 10       Vidro\n",
       "362012 2024-12-31    Circuito 11  Embalagens\n",
       "362080 2024-12-31    Circuito 12  Embalagens\n",
       "362222 2024-12-31    Circuito 12       Vidro\n",
       "\n",
       "[4948 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_base[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85bd3bbf-56c9-4f78-9fea-82382b3ca070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>info_adicional</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Vidro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 07</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 07</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377622</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Vidro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377635</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 06</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377666</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 12</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377669</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 02</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377748</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>Circuito 04</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8509 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             data info_adicional        tipo\n",
       "0      2024-01-02    Circ. Ilhas  Embalagens\n",
       "1      2024-01-02    Circ. Ilhas       Vidro\n",
       "5      2024-01-02    Circ. Ilhas       Papel\n",
       "10     2024-01-02    Circuito 07  Embalagens\n",
       "11     2024-01-02    Circuito 07       Papel\n",
       "...           ...            ...         ...\n",
       "377622 2024-12-31    Circuito 12       Vidro\n",
       "377635 2024-12-31    Circuito 06       Papel\n",
       "377666 2024-12-31    Circuito 12       Papel\n",
       "377669 2024-12-31    Circuito 02       Papel\n",
       "377748 2024-12-31    Circuito 04       Papel\n",
       "\n",
       "[8509 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copia[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a4bda68-4a45-4dfc-9828-046be8c8cd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas únicas em df_merge_base: 4948\n",
      "Linhas únicas em df_copia: 8509\n"
     ]
    }
   ],
   "source": [
    "# Conta o número de linhas únicas com base nas colunas desejadas\n",
    "base_unicos = df_merge_base[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates().shape[0]\n",
    "copia_unicos = df_copia[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates().shape[0]\n",
    "\n",
    "print(f\"Linhas únicas em df_merge_base: {base_unicos}\")\n",
    "print(f\"Linhas únicas em df_copia: {copia_unicos}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "498f1e7b-b8a1-4987-8808-71fee8d6c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas únicas que estão apenas no df_copia: 4611\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>info_adicional</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Vidro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 09</td>\n",
       "      <td>Vidro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 10</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Circuito 08</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data info_adicional        tipo\n",
       "1  2024-01-02    Circ. Ilhas       Vidro\n",
       "2  2024-01-02    Circ. Ilhas       Papel\n",
       "7  2024-01-02    Circuito 09       Vidro\n",
       "9  2024-01-02    Circuito 10  Embalagens\n",
       "12 2024-01-02    Circuito 08  Embalagens"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base_unique = df_merge_base[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates()\n",
    "df_copia_unique = df_copia[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates()\n",
    "\n",
    "# Faz o merge para encontrar diferenças\n",
    "df_diferenca = df_copia_unique.merge(df_base_unique, \n",
    "                                     on=[\"data\", \"info_adicional\", \"tipo\"], \n",
    "                                     how='left', \n",
    "                                     indicator=True)\n",
    "\n",
    "# Filtra apenas os que estão só no df_copia\n",
    "df_so_no_copia = df_diferenca[df_diferenca['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "print(f\"Número de linhas únicas que estão apenas no df_copia: {df_so_no_copia.shape[0]}\")\n",
    "df_so_no_copia.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6dabf5c-3832-4678-a875-9129b178cf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas únicas que estão apenas no df_merge_base: 1050\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>info_adicional</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>Circ. Ilhas</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>Circuito 04</td>\n",
       "      <td>Embalagens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>Circuito 04</td>\n",
       "      <td>Vidro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>Circuito 07</td>\n",
       "      <td>Papel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data info_adicional        tipo\n",
       "12 2024-03-01    Circ. Ilhas       Papel\n",
       "26 2024-04-01    Circ. Ilhas  Embalagens\n",
       "35 2024-04-01    Circuito 04  Embalagens\n",
       "36 2024-04-01    Circuito 04       Vidro\n",
       "42 2024-04-01    Circuito 07       Papel"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base_unique = df_merge_base[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates()\n",
    "df_copia_unique = df_copia[[\"data\", \"info_adicional\", \"tipo\"]].drop_duplicates()\n",
    "\n",
    "# Agora, invertemos o merge: partimos do df_merge_base\n",
    "df_diferenca_inversa = df_base_unique.merge(\n",
    "    df_copia_unique,\n",
    "    on=[\"data\", \"info_adicional\", \"tipo\"],\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "# Pegamos apenas as linhas que estão apenas no df_merge_base\n",
    "df_so_no_base = df_diferenca_inversa[df_diferenca_inversa['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "print(f\"Número de linhas únicas que estão apenas no df_merge_base: {df_so_no_base.shape[0]}\")\n",
    "df_so_no_base.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d9203-94ac-409a-8d77-1db56ab757ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100581a2-2edf-4521-ae48-06b709fad058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34608e57-cbef-4ee2-8478-828deff60913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d73203-9764-4938-a258-5fce465d9c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc66946-508d-483e-bd0d-a95c982d4601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d9d5ff-96e5-49f8-9dd9-2115f229b38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837626e6-d3e3-4003-8c90-a6392d4515d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bfa19-bb7b-43b2-a3b9-50fa48f21bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7cde2-ce04-472d-894e-64931e03ef93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7254f0-47d2-4d8a-bbb0-1003f32b1304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d09ac1c-da89-4829-8931-fc86e97b7d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rolling_1m, rolling_3m, rolling_1m_nivel, rolling_3m_nivel \u001b[38;5;241m=\u001b[39m calcular_estats(df_copia)\n",
      "Cell \u001b[1;32mIn[18], line 12\u001b[0m, in \u001b[0;36mcalcular_estats\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalcular_estats\u001b[39m(df):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Calcula estatísticas móveis (rolling statistics) para diferentes janelas de tempo\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    (30 e 90 dias) sobre as colunas relacionadas a níveis e taxas, aplicando agregações\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    das estatísticas por janela e tipo de métrica.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     rolling_1m \u001b[38;5;241m=\u001b[39m rolling_stats(df, \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     13\u001b[0m     rolling_3m \u001b[38;5;241m=\u001b[39m rolling_stats(df, \u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m     15\u001b[0m     rolling_1m_nivel \u001b[38;5;241m=\u001b[39m rolling_stats_nivel(df, \u001b[38;5;241m30\u001b[39m)\n",
      "Cell \u001b[1;32mIn[23], line 22\u001b[0m, in \u001b[0;36mrolling_stats\u001b[1;34m(df, window)\u001b[0m\n\u001b[0;32m     15\u001b[0m group \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     16\u001b[0m group\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(group\u001b[38;5;241m.\u001b[39mindex)  \u001b[38;5;66;03m# Garante que o índice seja datetime\u001b[39;00m\n\u001b[0;32m     18\u001b[0m group_rolled \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     19\u001b[0m     group[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_nivel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_tempo_horas\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaxa_enchimento_hora\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;241m.\u001b[39mrolling(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_nivel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, q1, q3],\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta_tempo_horas\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, q1, q3],\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaxa_enchimento_hora\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, q1, q3]\n\u001b[0;32m     26\u001b[0m     })\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Renomeia colunas\u001b[39;00m\n\u001b[0;32m     30\u001b[0m group_rolled\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m group_rolled\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     33\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1921\u001b[0m, in \u001b[0;36mRolling.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   1884\u001b[0m     _shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1885\u001b[0m     see_also\u001b[38;5;241m=\u001b[39mdedent(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1919\u001b[0m )\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:709\u001b[0m, in \u001b[0;36mBaseWindow.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 709\u001b[0m     result \u001b[38;5;241m=\u001b[39m ResamplerWindowApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    711\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(func, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\apply.py:172\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(arg):\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\apply.py:504\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    501\u001b[0m     results \u001b[38;5;241m=\u001b[39m {key: colg\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    505\u001b[0m         key: obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    506\u001b[0m     }\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# set the final keys\u001b[39;00m\n\u001b[0;32m    509\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\apply.py:505\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    501\u001b[0m     results \u001b[38;5;241m=\u001b[39m {key: colg\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m    504\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m--> 505\u001b[0m         key: obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    506\u001b[0m     }\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# set the final keys\u001b[39;00m\n\u001b[0;32m    509\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1921\u001b[0m, in \u001b[0;36mRolling.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   1884\u001b[0m     _shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1885\u001b[0m     see_also\u001b[38;5;241m=\u001b[39mdedent(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1919\u001b[0m )\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:709\u001b[0m, in \u001b[0;36mBaseWindow.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 709\u001b[0m     result \u001b[38;5;241m=\u001b[39m ResamplerWindowApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m    710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    711\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(func, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\apply.py:175\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(arg):\n\u001b[0;32m    178\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(arg)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\apply.py:378\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    376\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(selected_obj\u001b[38;5;241m.\u001b[39mname, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     new_res \u001b[38;5;241m=\u001b[39m colg\u001b[38;5;241m.\u001b[39maggregate(a)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     failed_names\u001b[38;5;241m.\u001b[39mappend(com\u001b[38;5;241m.\u001b[39mget_callable_name(a) \u001b[38;5;129;01mor\u001b[39;00m a)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1921\u001b[0m, in \u001b[0;36mRolling.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   1884\u001b[0m     _shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1885\u001b[0m     see_also\u001b[38;5;241m=\u001b[39mdedent(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1919\u001b[0m )\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:711\u001b[0m, in \u001b[0;36mBaseWindow.aggregate\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    709\u001b[0m result \u001b[38;5;241m=\u001b[39m ResamplerWindowApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(func, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:2000\u001b[0m, in \u001b[0;36mRolling.apply\u001b[1;34m(self, func, raw, engine, engine_kwargs, args, kwargs)\u001b[0m\n\u001b[0;32m   1979\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   1980\u001b[0m     template_header,\n\u001b[0;32m   1981\u001b[0m     create_section_header(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1998\u001b[0m     kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1999\u001b[0m ):\n\u001b[1;32m-> 2000\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m   2001\u001b[0m         func,\n\u001b[0;32m   2002\u001b[0m         raw\u001b[38;5;241m=\u001b[39mraw,\n\u001b[0;32m   2003\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   2004\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m   2005\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2006\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   2007\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1422\u001b[0m, in \u001b[0;36mRollingAndExpandingMixin.apply\u001b[1;34m(self, func, raw, engine, engine_kwargs, args, kwargs)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine must be either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumba\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcython\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\n\u001b[0;32m   1423\u001b[0m     apply_func,\n\u001b[0;32m   1424\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1425\u001b[0m     numba_args\u001b[38;5;241m=\u001b[39mnumba_args,\n\u001b[0;32m   1426\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:663\u001b[0m, in \u001b[0;36mBaseWindow._apply\u001b[1;34m(self, func, name, numeric_only, numba_args, **kwargs)\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_blockwise(homogeneous_func, name, numeric_only)\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_tablewise(homogeneous_func, name, numeric_only)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:503\u001b[0m, in \u001b[0;36mBaseWindow._apply_blockwise\u001b[1;34m(self, homogeneous_func, name, numeric_only)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_numeric_only(name, numeric_only)\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_series(homogeneous_func, name)\n\u001b[0;32m    505\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, numeric_only)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;66;03m# GH 12541: Special case for count where we support date-like types\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:487\u001b[0m, in \u001b[0;36mBaseWindow._apply_series\u001b[1;34m(self, homogeneous_func, name)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo numeric types to aggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m result \u001b[38;5;241m=\u001b[39m homogeneous_func(values)\n\u001b[0;32m    488\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_axis_for_step(obj\u001b[38;5;241m.\u001b[39mindex, result)\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor(result, index\u001b[38;5;241m=\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:658\u001b[0m, in \u001b[0;36mBaseWindow._apply.<locals>.homogeneous_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, start, end, min_periods, \u001b[38;5;241m*\u001b[39mnumba_args)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 658\u001b[0m     result \u001b[38;5;241m=\u001b[39m calc(values)\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:655\u001b[0m, in \u001b[0;36mBaseWindow._apply.<locals>.homogeneous_func.<locals>.calc\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    646\u001b[0m start, end \u001b[38;5;241m=\u001b[39m window_indexer\u001b[38;5;241m.\u001b[39mget_window_bounds(\n\u001b[0;32m    647\u001b[0m     num_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x),\n\u001b[0;32m    648\u001b[0m     min_periods\u001b[38;5;241m=\u001b[39mmin_periods,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m     step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep,\n\u001b[0;32m    652\u001b[0m )\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_window_bounds(start, end, \u001b[38;5;28mlen\u001b[39m(x))\n\u001b[1;32m--> 655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(x, start, end, min_periods, \u001b[38;5;241m*\u001b[39mnumba_args)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1449\u001b[0m, in \u001b[0;36mRollingAndExpandingMixin._generate_cython_apply_func.<locals>.apply_func\u001b[1;34m(values, begin, end, min_periods, raw)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw:\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;66;03m# GH 45912\u001b[39;00m\n\u001b[0;32m   1448\u001b[0m     values \u001b[38;5;241m=\u001b[39m Series(values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on)\n\u001b[1;32m-> 1449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m window_func(values, begin, end, min_periods)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\_libs\\window\\aggregations.pyx:1410\u001b[0m, in \u001b[0;36mpandas._libs.window.aggregations.roll_apply\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mq1\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mq1\u001b[39m(x):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\series.py:2683\u001b[0m, in \u001b[0;36mSeries.quantile\u001b[1;34m(self, q, interpolation)\u001b[0m\n\u001b[0;32m   2679\u001b[0m \u001b[38;5;66;03m# We dispatch to DataFrame so that core.internals only has to worry\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m \u001b[38;5;66;03m#  about 2D cases.\u001b[39;00m\n\u001b[0;32m   2681\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m-> 2683\u001b[0m result \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mquantile(q\u001b[38;5;241m=\u001b[39mq, interpolation\u001b[38;5;241m=\u001b[39minterpolation, numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   2685\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\frame.py:11274\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[1;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[0;32m  11267\u001b[0m numeric_only \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mresolve_numeric_only(numeric_only)\n\u001b[0;32m  11269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(q):\n\u001b[0;32m  11270\u001b[0m     \u001b[38;5;66;03m# BlockManager.quantile expects listlike, so we wrap and unwrap here\u001b[39;00m\n\u001b[0;32m  11271\u001b[0m     \u001b[38;5;66;03m# error: List item 0 has incompatible type \"Union[float, Union[Union[\u001b[39;00m\n\u001b[0;32m  11272\u001b[0m     \u001b[38;5;66;03m# ExtensionArray, ndarray[Any, Any]], Index, Series], Sequence[float]]\";\u001b[39;00m\n\u001b[0;32m  11273\u001b[0m     \u001b[38;5;66;03m# expected \"float\"\u001b[39;00m\n\u001b[1;32m> 11274\u001b[0m     res_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantile(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m  11275\u001b[0m         [q],\n\u001b[0;32m  11276\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m  11277\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m  11278\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m  11279\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m  11280\u001b[0m     )\n\u001b[0;32m  11281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11282\u001b[0m         res \u001b[38;5;241m=\u001b[39m res_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\frame.py:11321\u001b[0m, in \u001b[0;36mDataFrame.quantile\u001b[1;34m(self, q, axis, numeric_only, interpolation, method)\u001b[0m\n\u001b[0;32m  11315\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m  11316\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Method must be in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  11317\u001b[0m     )\n\u001b[0;32m  11318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11319\u001b[0m     \u001b[38;5;66;03m# error: Argument \"qs\" to \"quantile\" of \"BlockManager\" has incompatible type\u001b[39;00m\n\u001b[0;32m  11320\u001b[0m     \u001b[38;5;66;03m# \"Index\"; expected \"Float64Index\"\u001b[39;00m\n\u001b[1;32m> 11321\u001b[0m     res \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mquantile(\n\u001b[0;32m  11322\u001b[0m         qs\u001b[38;5;241m=\u001b[39mq, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39minterpolation  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m  11323\u001b[0m     )\n\u001b[0;32m  11324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11325\u001b[0m     valid_interpolation \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlower\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigher\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1631\u001b[0m, in \u001b[0;36mBlockManager.quantile\u001b[1;34m(self, qs, axis, interpolation)\u001b[0m\n\u001b[0;32m   1628\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   1629\u001b[0m new_axes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m Float64Index(qs)\n\u001b[1;32m-> 1631\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1632\u001b[0m     blk\u001b[38;5;241m.\u001b[39mquantile(axis\u001b[38;5;241m=\u001b[39maxis, qs\u001b[38;5;241m=\u001b[39mqs, interpolation\u001b[38;5;241m=\u001b[39minterpolation)\n\u001b[0;32m   1633\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1634\u001b[0m ]\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1632\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1628\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   1629\u001b[0m new_axes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m Float64Index(qs)\n\u001b[0;32m   1631\u001b[0m blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m-> 1632\u001b[0m     blk\u001b[38;5;241m.\u001b[39mquantile(axis\u001b[38;5;241m=\u001b[39maxis, qs\u001b[38;5;241m=\u001b[39mqs, interpolation\u001b[38;5;241m=\u001b[39minterpolation)\n\u001b[0;32m   1633\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m   1634\u001b[0m ]\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(blocks, new_axes)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1335\u001b[0m, in \u001b[0;36mBlock.quantile\u001b[1;34m(self, qs, interpolation, axis)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only ever called this way\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_list_like(qs)  \u001b[38;5;66;03m# caller is responsible for this\u001b[39;00m\n\u001b[1;32m-> 1335\u001b[0m result \u001b[38;5;241m=\u001b[39m quantile_compat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, np\u001b[38;5;241m.\u001b[39masarray(qs\u001b[38;5;241m.\u001b[39m_values), interpolation)\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;66;03m# ensure_block_shape needed for cases where we start with EA and result\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;66;03m#  is ndarray, e.g. IntegerArray, SparseArray\u001b[39;00m\n\u001b[0;32m   1338\u001b[0m result \u001b[38;5;241m=\u001b[39m ensure_block_shape(result, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:37\u001b[0m, in \u001b[0;36mquantile_compat\u001b[1;34m(values, qs, interpolation)\u001b[0m\n\u001b[0;32m     35\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m na_value_for_dtype(values\u001b[38;5;241m.\u001b[39mdtype, compat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m quantile_with_mask(values, mask, fill_value, qs, interpolation)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_quantile(qs, interpolation)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:95\u001b[0m, in \u001b[0;36mquantile_with_mask\u001b[1;34m(values, mask, fill_value, qs, interpolation)\u001b[0m\n\u001b[0;32m     93\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(flat, \u001b[38;5;28mlen\u001b[39m(values))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(values), \u001b[38;5;28mlen\u001b[39m(qs))\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m _nanpercentile(\n\u001b[0;32m     96\u001b[0m         values,\n\u001b[0;32m     97\u001b[0m         qs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m,\n\u001b[0;32m     98\u001b[0m         na_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m     99\u001b[0m         mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[0;32m    100\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    104\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\pandas\\core\\array_algos\\quantile.py:216\u001b[0m, in \u001b[0;36m_nanpercentile\u001b[1;34m(values, qs, na_value, mask, interpolation)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mpercentile(\n\u001b[0;32m    217\u001b[0m         values,\n\u001b[0;32m    218\u001b[0m         qs,\n\u001b[0;32m    219\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;66;03m# error: No overload variant of \"percentile\" matches argument types\u001b[39;00m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;66;03m# \"ndarray[Any, Any]\", \"ndarray[Any, dtype[floating[_64Bit]]]\",\u001b[39;00m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;66;03m# \"int\", \"Dict[str, str]\"  [call-overload]\u001b[39;00m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{np_percentile_argname: interpolation},  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\numpy\\lib\\function_base.py:4283\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[0;32m   4281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[0;32m   4282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentiles must be in the range [0, 100]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[0;32m   4284\u001b[0m     a, q, axis, out, overwrite_input, method, keepdims)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\numpy\\lib\\function_base.py:4555\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4548\u001b[0m                         q,\n\u001b[0;32m   4549\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4552\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4553\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   4554\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ureduce(a,\n\u001b[0;32m   4556\u001b[0m                     func\u001b[38;5;241m=\u001b[39m_quantile_ureduce_func,\n\u001b[0;32m   4557\u001b[0m                     q\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4558\u001b[0m                     keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   4559\u001b[0m                     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4560\u001b[0m                     out\u001b[38;5;241m=\u001b[39mout,\n\u001b[0;32m   4561\u001b[0m                     overwrite_input\u001b[38;5;241m=\u001b[39moverwrite_input,\n\u001b[0;32m   4562\u001b[0m                     method\u001b[38;5;241m=\u001b[39mmethod)\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\numpy\\lib\\function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[0;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[1;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m func(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\numpy\\lib\\function_base.py:4722\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4721\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 4722\u001b[0m result \u001b[38;5;241m=\u001b[39m _quantile(arr,\n\u001b[0;32m   4723\u001b[0m                    quantiles\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4724\u001b[0m                    axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4725\u001b[0m                    method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   4726\u001b[0m                    out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m   4727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda5\\envs\\maenvs\\Lib\\site-packages\\numpy\\lib\\function_base.py:4825\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[0;32m   4820\u001b[0m previous_indexes, next_indexes \u001b[38;5;241m=\u001b[39m _get_indexes(arr,\n\u001b[0;32m   4821\u001b[0m                                               virtual_indexes,\n\u001b[0;32m   4822\u001b[0m                                               values_count)\n\u001b[0;32m   4823\u001b[0m \u001b[38;5;66;03m# --- Sorting\u001b[39;00m\n\u001b[0;32m   4824\u001b[0m arr\u001b[38;5;241m.\u001b[39mpartition(\n\u001b[1;32m-> 4825\u001b[0m     np\u001b[38;5;241m.\u001b[39munique(np\u001b[38;5;241m.\u001b[39mconcatenate(([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   4826\u001b[0m                               previous_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m   4827\u001b[0m                               next_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m   4828\u001b[0m                               ))),\n\u001b[0;32m   4829\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   4830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supports_nans:\n\u001b[0;32m   4831\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(arr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rolling_1m, rolling_3m, rolling_1m_nivel, rolling_3m_nivel = calcular_estats(df_copia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93cbb88-e631-4ba3-9a6b-1cc514f72471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simao\\AppData\\Local\\Temp\\ipykernel_22488\\2605845511.py:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(['info_adicional', 'local_id'], group_keys=False).apply(cluster_sessions)\n",
      "C:\\Users\\simao\\AppData\\Local\\Temp\\ipykernel_22488\\639862392.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(calcular_deltas)\n"
     ]
    }
   ],
   "source": [
    "df_final=merge(df_merge_base, rolling_1m, rolling_3m, rolling_1m_nivel, rolling_3m_nivel)\n",
    "df_final = df_final.rename(columns={'data': 'Data'})\n",
    "df_final = df_final.rename(columns={'info_adicional': 'Circuito'})\n",
    "df_final = df_final.rename(columns={'tipo': 'Tipo'})\n",
    "df_final.to_csv(\"../data/taxas_e_estatisticas.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "509c734e-be41-42a6-8e23-9f611abb8f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190af26-d25c-4ac5-9dbf-cbd7a2d118c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
